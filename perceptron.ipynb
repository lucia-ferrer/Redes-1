{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMih1Ww83GJk4C8UWYdkpBn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia-ferrer/Redes-1/blob/pm/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar colab - **github**"
      ],
      "metadata": {
        "id": "UX1I6z0_nxZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lucia-ferrer/Redes-1.git"
      ],
      "metadata": {
        "id": "c053X5mSnuv4",
        "outputId": "89270bcd-298a-4b3a-af99-0a13a838ca6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Redes-1'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 55 (delta 18), reused 37 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Perceptron**"
      ],
      "metadata": {
        "id": "fviwaUsLn3i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Regression problem: MLP con Keras \"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# CARGAR DATOS compactiv\n",
        "# Cambiar par치metros correspondientes si el delimitador no es una coma, o si el archivo contiene cabeceras\n",
        "#pueden ser numpy arrays o dataframes\n",
        "#en este caso probamos con ndarrays\n",
        "train_set = pd.read_csv('/content/Redes-1/training_set.csv', header='infer', delimiter=',')\n",
        "valid_set = pd.read_csv('/content/Redes-1/validation_set.csv', header='infer', delimiter=',')\n",
        "test_set = pd.read_csv('/content/Redes-1/validation_set.csv', header='infer', delimiter=',')\n",
        "\n",
        "# SELECCION DE LA SALIDA. Num de columna del target.\n",
        "y_train = np.array(train_set.iloc[:,-1:])\n",
        "X_train = np.array(train_set.iloc[: , :-1])\n",
        "y_valid = np.array(valid_set.iloc[:,-1:])\n",
        "X_valid = np.array(valid_set.iloc[: , :-1])\n",
        "y_test = np.array(test_set.iloc[:,-1:])\n",
        "X_test = np.array(test_set.iloc[: , :-1])\n",
        "num_train_samples=len(y_train)\n"
      ],
      "metadata": {
        "id": "Gwt4RT1ekrCW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPROBAR DIMENSIONES DE LOS DATOS\n",
        "print('X_train: ',X_train.shape)\n",
        "print('y_train: ',y_train.shape)\n",
        "print('X_valid: ',X_valid.shape)\n",
        "print('y_valid: ',y_valid.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "metadata": {
        "id": "vOCztVDLp-E0",
        "outputId": "09512356-e1c5-4faa-ded7-9bde958504d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (5733, 21)\n",
            "y_train:  (5733, 1)\n",
            "X_valid:  (1228, 21)\n",
            "y_valid:  (1228, 1)\n",
            "X_test:  (1228, 21)\n",
            "y_test:  (1228, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la entrada de la red\n",
        "input_shape=(X_train.shape [1],) #crea una tupla (21,)\n",
        "\n",
        "#funciones con diferentes modelos\n",
        "def create_PM_sigmoid(num_hidden_neurons = 50):\n",
        "  #1 capa oculta y 1 neurona de salida con sigmoide\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def create_PM_relu(num_hidden_neurons = 50):\n",
        "  #1 capa oculta con relu y 1 neurona de salida lineal\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dense(1,activation='linear'))\n",
        "  return model\n",
        "\n",
        "#modelo lineal, solo para comparar con el programa desarrollado.\n",
        "def create_lineal():\n",
        "  # Una sola neurona lineal (Adaline)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1, input_shape=input_shape, activation='linear'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "A__kABVUqIk-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionar el modelo llamando a la funci칩n correspondiente\n",
        "model=create_PM_relu(20) # 1 capa relu con 20 neuronas y salida lineal\n",
        "#model=create_PM_sigmoid(20) # 1 capa sigmoid con 20 neuronas y salida sigmoid\n",
        "#model=create_lineal() # 1 capa salida LINEAL (ADALINE)\n",
        "model.summary() #visualizar la estructura del modelo\n"
      ],
      "metadata": {
        "id": "y8NNJ_mRqTrF",
        "outputId": "08ab8dd1-715d-4db6-d121-cc5f72fba50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                440       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
        "lr = 0.2\n",
        "epochs = 300\n",
        "batch_size=32 #no cambiar este valor.\n",
        "#Para poder ver la curva de validaci칩n hay que poner validation_freq=1. Tarda m치s\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0), metrics=['mse'] )\n",
        "historico = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(X_valid,y_valid),\n",
        "shuffle=False, validation_freq=1)\n"
      ],
      "metadata": {
        "id": "yZksWPqTqYYZ",
        "outputId": "ef88340e-564f-40d7-b6ef-8a2ba7dbc5e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "180/180 [==============================] - 1s 2ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 2/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0063 - val_mse: 0.0063\n",
            "Epoch 3/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 4/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 5/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 6/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 7/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 8/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 9/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 10/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 11/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 12/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 13/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 14/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 15/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 16/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 17/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 9.9708e-04 - mse: 9.9708e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 18/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 9.6805e-04 - mse: 9.6805e-04 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 19/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 9.4259e-04 - mse: 9.4259e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 20/300\n",
            "180/180 [==============================] - 0s 3ms/step - loss: 9.2138e-04 - mse: 9.2138e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 21/300\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 9.0339e-04 - mse: 9.0339e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 22/300\n",
            "180/180 [==============================] - 1s 5ms/step - loss: 8.8804e-04 - mse: 8.8804e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 23/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 8.7390e-04 - mse: 8.7390e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 24/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.6125e-04 - mse: 8.6125e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 25/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.5030e-04 - mse: 8.5030e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 26/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.4013e-04 - mse: 8.4013e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 27/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.3116e-04 - mse: 8.3116e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 28/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.2294e-04 - mse: 8.2294e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 29/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.1571e-04 - mse: 8.1571e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 30/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.0914e-04 - mse: 8.0914e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 31/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 8.0322e-04 - mse: 8.0322e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 32/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.9782e-04 - mse: 7.9782e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 33/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.9282e-04 - mse: 7.9282e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 34/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.8801e-04 - mse: 7.8801e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 35/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.8354e-04 - mse: 7.8354e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 36/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.7917e-04 - mse: 7.7917e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 37/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.7513e-04 - mse: 7.7513e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 38/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.7136e-04 - mse: 7.7136e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 39/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.6792e-04 - mse: 7.6792e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 40/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.6463e-04 - mse: 7.6463e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 41/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.6146e-04 - mse: 7.6146e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 42/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.5843e-04 - mse: 7.5843e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 43/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.5550e-04 - mse: 7.5550e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 44/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.5266e-04 - mse: 7.5266e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 45/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.4993e-04 - mse: 7.4993e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 46/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.4735e-04 - mse: 7.4735e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 47/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.4488e-04 - mse: 7.4488e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 48/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.4248e-04 - mse: 7.4248e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 49/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.4008e-04 - mse: 7.4008e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 50/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.3787e-04 - mse: 7.3787e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 51/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.3579e-04 - mse: 7.3579e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 52/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.3378e-04 - mse: 7.3378e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 53/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.3172e-04 - mse: 7.3172e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 54/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2982e-04 - mse: 7.2982e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 55/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2794e-04 - mse: 7.2794e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 56/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2613e-04 - mse: 7.2613e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 57/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2442e-04 - mse: 7.2442e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 58/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2268e-04 - mse: 7.2268e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 59/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.2119e-04 - mse: 7.2119e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 60/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1963e-04 - mse: 7.1963e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 61/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1821e-04 - mse: 7.1821e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 62/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1683e-04 - mse: 7.1683e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 63/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1552e-04 - mse: 7.1552e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 64/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1423e-04 - mse: 7.1423e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 65/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.1298e-04 - mse: 7.1298e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 66/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 7.1177e-04 - mse: 7.1177e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 67/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 7.1049e-04 - mse: 7.1049e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 68/300\n",
            "180/180 [==============================] - 0s 3ms/step - loss: 7.0931e-04 - mse: 7.0931e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 69/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0813e-04 - mse: 7.0813e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 70/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0697e-04 - mse: 7.0697e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 71/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0589e-04 - mse: 7.0589e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 72/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0477e-04 - mse: 7.0477e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 73/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0376e-04 - mse: 7.0376e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 74/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0283e-04 - mse: 7.0283e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 75/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0185e-04 - mse: 7.0185e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 76/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 7.0082e-04 - mse: 7.0082e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 77/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9987e-04 - mse: 6.9987e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 78/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9886e-04 - mse: 6.9886e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 79/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9794e-04 - mse: 6.9794e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 80/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9704e-04 - mse: 6.9704e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 81/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9616e-04 - mse: 6.9616e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 82/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9525e-04 - mse: 6.9525e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 83/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9437e-04 - mse: 6.9437e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 84/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9348e-04 - mse: 6.9348e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 85/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9266e-04 - mse: 6.9266e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 86/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9179e-04 - mse: 6.9179e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 87/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9099e-04 - mse: 6.9099e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 88/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.9017e-04 - mse: 6.9017e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 89/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8940e-04 - mse: 6.8940e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 90/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8864e-04 - mse: 6.8864e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 91/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8789e-04 - mse: 6.8789e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 92/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8711e-04 - mse: 6.8711e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 93/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8646e-04 - mse: 6.8646e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 94/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8574e-04 - mse: 6.8574e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 95/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8502e-04 - mse: 6.8502e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 96/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8433e-04 - mse: 6.8433e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 97/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8369e-04 - mse: 6.8369e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 98/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8303e-04 - mse: 6.8303e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 99/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8237e-04 - mse: 6.8237e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 100/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8172e-04 - mse: 6.8172e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 101/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8108e-04 - mse: 6.8108e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 102/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.8038e-04 - mse: 6.8038e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 103/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7974e-04 - mse: 6.7974e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 104/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7915e-04 - mse: 6.7915e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 105/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7854e-04 - mse: 6.7854e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 106/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7792e-04 - mse: 6.7792e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 107/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7734e-04 - mse: 6.7734e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 108/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7675e-04 - mse: 6.7675e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 109/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7613e-04 - mse: 6.7613e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 110/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7546e-04 - mse: 6.7546e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 111/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7490e-04 - mse: 6.7490e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 112/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7440e-04 - mse: 6.7440e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 113/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7384e-04 - mse: 6.7384e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 114/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7334e-04 - mse: 6.7334e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 115/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7313e-04 - mse: 6.7313e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 116/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7234e-04 - mse: 6.7234e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 117/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7206e-04 - mse: 6.7206e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 118/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7140e-04 - mse: 6.7140e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 119/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7111e-04 - mse: 6.7111e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 120/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7040e-04 - mse: 6.7040e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 121/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.7021e-04 - mse: 6.7021e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 122/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6971e-04 - mse: 6.6971e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 123/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6905e-04 - mse: 6.6905e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 124/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6882e-04 - mse: 6.6882e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 125/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6818e-04 - mse: 6.6818e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 126/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6796e-04 - mse: 6.6796e-04 - val_loss: 9.9864e-04 - val_mse: 9.9864e-04\n",
            "Epoch 127/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6732e-04 - mse: 6.6732e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 128/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6711e-04 - mse: 6.6711e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 129/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6669e-04 - mse: 6.6669e-04 - val_loss: 9.9752e-04 - val_mse: 9.9752e-04\n",
            "Epoch 130/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6600e-04 - mse: 6.6600e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 131/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6579e-04 - mse: 6.6579e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 132/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6533e-04 - mse: 6.6533e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 133/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6492e-04 - mse: 6.6492e-04 - val_loss: 9.9575e-04 - val_mse: 9.9575e-04\n",
            "Epoch 134/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6429e-04 - mse: 6.6429e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 135/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6412e-04 - mse: 6.6412e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 136/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6372e-04 - mse: 6.6372e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 137/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6334e-04 - mse: 6.6334e-04 - val_loss: 9.9380e-04 - val_mse: 9.9380e-04\n",
            "Epoch 138/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6277e-04 - mse: 6.6277e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 139/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6261e-04 - mse: 6.6261e-04 - val_loss: 9.9965e-04 - val_mse: 9.9965e-04\n",
            "Epoch 140/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6226e-04 - mse: 6.6226e-04 - val_loss: 9.9236e-04 - val_mse: 9.9236e-04\n",
            "Epoch 141/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6167e-04 - mse: 6.6167e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 142/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6154e-04 - mse: 6.6154e-04 - val_loss: 9.9863e-04 - val_mse: 9.9863e-04\n",
            "Epoch 143/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6117e-04 - mse: 6.6117e-04 - val_loss: 9.9140e-04 - val_mse: 9.9140e-04\n",
            "Epoch 144/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6058e-04 - mse: 6.6058e-04 - val_loss: 9.9938e-04 - val_mse: 9.9938e-04\n",
            "Epoch 145/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6046e-04 - mse: 6.6046e-04 - val_loss: 9.9790e-04 - val_mse: 9.9790e-04\n",
            "Epoch 146/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.6013e-04 - mse: 6.6013e-04 - val_loss: 9.9646e-04 - val_mse: 9.9646e-04\n",
            "Epoch 147/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5977e-04 - mse: 6.5977e-04 - val_loss: 9.9034e-04 - val_mse: 9.9034e-04\n",
            "Epoch 148/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5924e-04 - mse: 6.5924e-04 - val_loss: 9.9720e-04 - val_mse: 9.9720e-04\n",
            "Epoch 149/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5911e-04 - mse: 6.5911e-04 - val_loss: 9.9550e-04 - val_mse: 9.9550e-04\n",
            "Epoch 150/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5876e-04 - mse: 6.5876e-04 - val_loss: 9.8913e-04 - val_mse: 9.8913e-04\n",
            "Epoch 151/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5824e-04 - mse: 6.5824e-04 - val_loss: 9.9565e-04 - val_mse: 9.9565e-04\n",
            "Epoch 152/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5812e-04 - mse: 6.5812e-04 - val_loss: 9.8806e-04 - val_mse: 9.8806e-04\n",
            "Epoch 153/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5758e-04 - mse: 6.5758e-04 - val_loss: 9.9553e-04 - val_mse: 9.9553e-04\n",
            "Epoch 154/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5747e-04 - mse: 6.5747e-04 - val_loss: 9.9362e-04 - val_mse: 9.9362e-04\n",
            "Epoch 155/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5715e-04 - mse: 6.5715e-04 - val_loss: 9.8672e-04 - val_mse: 9.8672e-04\n",
            "Epoch 156/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5662e-04 - mse: 6.5662e-04 - val_loss: 9.9418e-04 - val_mse: 9.9418e-04\n",
            "Epoch 157/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5654e-04 - mse: 6.5654e-04 - val_loss: 9.9236e-04 - val_mse: 9.9236e-04\n",
            "Epoch 158/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5624e-04 - mse: 6.5624e-04 - val_loss: 9.8540e-04 - val_mse: 9.8540e-04\n",
            "Epoch 159/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5571e-04 - mse: 6.5571e-04 - val_loss: 9.9296e-04 - val_mse: 9.9296e-04\n",
            "Epoch 160/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5562e-04 - mse: 6.5562e-04 - val_loss: 9.9097e-04 - val_mse: 9.9097e-04\n",
            "Epoch 161/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5532e-04 - mse: 6.5532e-04 - val_loss: 9.8403e-04 - val_mse: 9.8403e-04\n",
            "Epoch 162/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5488e-04 - mse: 6.5488e-04 - val_loss: 9.9473e-04 - val_mse: 9.9473e-04\n",
            "Epoch 163/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5481e-04 - mse: 6.5481e-04 - val_loss: 9.9421e-04 - val_mse: 9.9421e-04\n",
            "Epoch 164/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5448e-04 - mse: 6.5448e-04 - val_loss: 9.9314e-04 - val_mse: 9.9314e-04\n",
            "Epoch 165/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5423e-04 - mse: 6.5423e-04 - val_loss: 9.9250e-04 - val_mse: 9.9250e-04\n",
            "Epoch 166/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5395e-04 - mse: 6.5395e-04 - val_loss: 9.9133e-04 - val_mse: 9.9133e-04\n",
            "Epoch 167/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5368e-04 - mse: 6.5368e-04 - val_loss: 9.8428e-04 - val_mse: 9.8428e-04\n",
            "Epoch 168/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5316e-04 - mse: 6.5316e-04 - val_loss: 9.9283e-04 - val_mse: 9.9283e-04\n",
            "Epoch 169/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5315e-04 - mse: 6.5315e-04 - val_loss: 9.9141e-04 - val_mse: 9.9141e-04\n",
            "Epoch 170/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5288e-04 - mse: 6.5288e-04 - val_loss: 9.9024e-04 - val_mse: 9.9024e-04\n",
            "Epoch 171/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5263e-04 - mse: 6.5263e-04 - val_loss: 9.9003e-04 - val_mse: 9.9003e-04\n",
            "Epoch 172/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5242e-04 - mse: 6.5242e-04 - val_loss: 9.9018e-04 - val_mse: 9.9018e-04\n",
            "Epoch 173/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5214e-04 - mse: 6.5214e-04 - val_loss: 9.8947e-04 - val_mse: 9.8947e-04\n",
            "Epoch 174/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5192e-04 - mse: 6.5192e-04 - val_loss: 9.9019e-04 - val_mse: 9.9019e-04\n",
            "Epoch 175/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5170e-04 - mse: 6.5170e-04 - val_loss: 9.8924e-04 - val_mse: 9.8924e-04\n",
            "Epoch 176/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5140e-04 - mse: 6.5140e-04 - val_loss: 9.8289e-04 - val_mse: 9.8289e-04\n",
            "Epoch 177/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5096e-04 - mse: 6.5096e-04 - val_loss: 9.9116e-04 - val_mse: 9.9116e-04\n",
            "Epoch 178/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5094e-04 - mse: 6.5094e-04 - val_loss: 9.8913e-04 - val_mse: 9.8913e-04\n",
            "Epoch 179/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5071e-04 - mse: 6.5071e-04 - val_loss: 9.8818e-04 - val_mse: 9.8818e-04\n",
            "Epoch 180/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5049e-04 - mse: 6.5049e-04 - val_loss: 9.8181e-04 - val_mse: 9.8181e-04\n",
            "Epoch 181/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4997e-04 - mse: 6.4997e-04 - val_loss: 9.8958e-04 - val_mse: 9.8958e-04\n",
            "Epoch 182/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.5003e-04 - mse: 6.5003e-04 - val_loss: 9.8780e-04 - val_mse: 9.8780e-04\n",
            "Epoch 183/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4978e-04 - mse: 6.4978e-04 - val_loss: 9.8023e-04 - val_mse: 9.8023e-04\n",
            "Epoch 184/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4932e-04 - mse: 6.4932e-04 - val_loss: 9.8848e-04 - val_mse: 9.8848e-04\n",
            "Epoch 185/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4938e-04 - mse: 6.4938e-04 - val_loss: 9.8629e-04 - val_mse: 9.8629e-04\n",
            "Epoch 186/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4911e-04 - mse: 6.4911e-04 - val_loss: 9.7981e-04 - val_mse: 9.7981e-04\n",
            "Epoch 187/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4866e-04 - mse: 6.4866e-04 - val_loss: 9.8706e-04 - val_mse: 9.8706e-04\n",
            "Epoch 188/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4865e-04 - mse: 6.4865e-04 - val_loss: 9.8514e-04 - val_mse: 9.8514e-04\n",
            "Epoch 189/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4845e-04 - mse: 6.4845e-04 - val_loss: 9.7832e-04 - val_mse: 9.7832e-04\n",
            "Epoch 190/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4796e-04 - mse: 6.4796e-04 - val_loss: 9.8575e-04 - val_mse: 9.8575e-04\n",
            "Epoch 191/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4798e-04 - mse: 6.4798e-04 - val_loss: 9.8408e-04 - val_mse: 9.8408e-04\n",
            "Epoch 192/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4775e-04 - mse: 6.4775e-04 - val_loss: 9.7737e-04 - val_mse: 9.7737e-04\n",
            "Epoch 193/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4732e-04 - mse: 6.4732e-04 - val_loss: 9.8502e-04 - val_mse: 9.8502e-04\n",
            "Epoch 194/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4733e-04 - mse: 6.4733e-04 - val_loss: 9.7681e-04 - val_mse: 9.7681e-04\n",
            "Epoch 195/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4689e-04 - mse: 6.4689e-04 - val_loss: 9.8529e-04 - val_mse: 9.8529e-04\n",
            "Epoch 196/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4690e-04 - mse: 6.4690e-04 - val_loss: 9.8307e-04 - val_mse: 9.8307e-04\n",
            "Epoch 197/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4672e-04 - mse: 6.4672e-04 - val_loss: 9.7582e-04 - val_mse: 9.7582e-04\n",
            "Epoch 198/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4630e-04 - mse: 6.4630e-04 - val_loss: 9.8498e-04 - val_mse: 9.8498e-04\n",
            "Epoch 199/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4629e-04 - mse: 6.4629e-04 - val_loss: 9.8360e-04 - val_mse: 9.8360e-04\n",
            "Epoch 200/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4604e-04 - mse: 6.4604e-04 - val_loss: 9.8238e-04 - val_mse: 9.8238e-04\n",
            "Epoch 201/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4585e-04 - mse: 6.4585e-04 - val_loss: 9.8144e-04 - val_mse: 9.8144e-04\n",
            "Epoch 202/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4567e-04 - mse: 6.4567e-04 - val_loss: 9.7558e-04 - val_mse: 9.7558e-04\n",
            "Epoch 203/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4528e-04 - mse: 6.4528e-04 - val_loss: 9.8275e-04 - val_mse: 9.8275e-04\n",
            "Epoch 204/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4530e-04 - mse: 6.4530e-04 - val_loss: 9.8246e-04 - val_mse: 9.8246e-04\n",
            "Epoch 205/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4508e-04 - mse: 6.4508e-04 - val_loss: 9.7452e-04 - val_mse: 9.7452e-04\n",
            "Epoch 206/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4473e-04 - mse: 6.4473e-04 - val_loss: 9.8296e-04 - val_mse: 9.8296e-04\n",
            "Epoch 207/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4474e-04 - mse: 6.4474e-04 - val_loss: 9.8072e-04 - val_mse: 9.8072e-04\n",
            "Epoch 208/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4457e-04 - mse: 6.4457e-04 - val_loss: 9.7349e-04 - val_mse: 9.7349e-04\n",
            "Epoch 209/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4415e-04 - mse: 6.4415e-04 - val_loss: 9.8119e-04 - val_mse: 9.8119e-04\n",
            "Epoch 210/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4424e-04 - mse: 6.4424e-04 - val_loss: 9.7325e-04 - val_mse: 9.7325e-04\n",
            "Epoch 211/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4385e-04 - mse: 6.4385e-04 - val_loss: 9.8099e-04 - val_mse: 9.8099e-04\n",
            "Epoch 212/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4390e-04 - mse: 6.4390e-04 - val_loss: 9.7996e-04 - val_mse: 9.7996e-04\n",
            "Epoch 213/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4363e-04 - mse: 6.4363e-04 - val_loss: 9.7298e-04 - val_mse: 9.7298e-04\n",
            "Epoch 214/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4334e-04 - mse: 6.4334e-04 - val_loss: 9.7925e-04 - val_mse: 9.7925e-04\n",
            "Epoch 215/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4334e-04 - mse: 6.4334e-04 - val_loss: 9.7298e-04 - val_mse: 9.7298e-04\n",
            "Epoch 216/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4295e-04 - mse: 6.4295e-04 - val_loss: 9.7963e-04 - val_mse: 9.7963e-04\n",
            "Epoch 217/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4300e-04 - mse: 6.4300e-04 - val_loss: 9.7314e-04 - val_mse: 9.7314e-04\n",
            "Epoch 218/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4259e-04 - mse: 6.4259e-04 - val_loss: 9.8122e-04 - val_mse: 9.8122e-04\n",
            "Epoch 219/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4264e-04 - mse: 6.4264e-04 - val_loss: 9.7347e-04 - val_mse: 9.7347e-04\n",
            "Epoch 220/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4223e-04 - mse: 6.4223e-04 - val_loss: 9.8275e-04 - val_mse: 9.8275e-04\n",
            "Epoch 221/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4234e-04 - mse: 6.4234e-04 - val_loss: 9.7362e-04 - val_mse: 9.7362e-04\n",
            "Epoch 222/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4196e-04 - mse: 6.4196e-04 - val_loss: 9.8389e-04 - val_mse: 9.8389e-04\n",
            "Epoch 223/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4196e-04 - mse: 6.4196e-04 - val_loss: 9.7206e-04 - val_mse: 9.7206e-04\n",
            "Epoch 224/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4154e-04 - mse: 6.4154e-04 - val_loss: 9.7214e-04 - val_mse: 9.7214e-04\n",
            "Epoch 225/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4136e-04 - mse: 6.4136e-04 - val_loss: 9.7211e-04 - val_mse: 9.7211e-04\n",
            "Epoch 226/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4117e-04 - mse: 6.4117e-04 - val_loss: 9.8052e-04 - val_mse: 9.8052e-04\n",
            "Epoch 227/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4132e-04 - mse: 6.4132e-04 - val_loss: 9.7308e-04 - val_mse: 9.7308e-04\n",
            "Epoch 228/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4087e-04 - mse: 6.4087e-04 - val_loss: 9.7988e-04 - val_mse: 9.7988e-04\n",
            "Epoch 229/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4092e-04 - mse: 6.4092e-04 - val_loss: 9.7349e-04 - val_mse: 9.7349e-04\n",
            "Epoch 230/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4048e-04 - mse: 6.4048e-04 - val_loss: 9.7344e-04 - val_mse: 9.7344e-04\n",
            "Epoch 231/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4032e-04 - mse: 6.4032e-04 - val_loss: 9.8023e-04 - val_mse: 9.8023e-04\n",
            "Epoch 232/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.4040e-04 - mse: 6.4040e-04 - val_loss: 9.7286e-04 - val_mse: 9.7286e-04\n",
            "Epoch 233/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3995e-04 - mse: 6.3995e-04 - val_loss: 9.7223e-04 - val_mse: 9.7223e-04\n",
            "Epoch 234/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3985e-04 - mse: 6.3985e-04 - val_loss: 9.8014e-04 - val_mse: 9.8014e-04\n",
            "Epoch 235/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3986e-04 - mse: 6.3986e-04 - val_loss: 9.7155e-04 - val_mse: 9.7155e-04\n",
            "Epoch 236/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3944e-04 - mse: 6.3944e-04 - val_loss: 9.7161e-04 - val_mse: 9.7161e-04\n",
            "Epoch 237/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3928e-04 - mse: 6.3928e-04 - val_loss: 9.7893e-04 - val_mse: 9.7893e-04\n",
            "Epoch 238/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3937e-04 - mse: 6.3937e-04 - val_loss: 9.7096e-04 - val_mse: 9.7096e-04\n",
            "Epoch 239/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3897e-04 - mse: 6.3897e-04 - val_loss: 9.7761e-04 - val_mse: 9.7761e-04\n",
            "Epoch 240/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3905e-04 - mse: 6.3905e-04 - val_loss: 9.7073e-04 - val_mse: 9.7073e-04\n",
            "Epoch 241/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3857e-04 - mse: 6.3857e-04 - val_loss: 9.6926e-04 - val_mse: 9.6926e-04\n",
            "Epoch 242/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3842e-04 - mse: 6.3842e-04 - val_loss: 9.7594e-04 - val_mse: 9.7594e-04\n",
            "Epoch 243/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3855e-04 - mse: 6.3855e-04 - val_loss: 9.6883e-04 - val_mse: 9.6883e-04\n",
            "Epoch 244/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3815e-04 - mse: 6.3815e-04 - val_loss: 9.6801e-04 - val_mse: 9.6801e-04\n",
            "Epoch 245/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3801e-04 - mse: 6.3801e-04 - val_loss: 9.7881e-04 - val_mse: 9.7881e-04\n",
            "Epoch 246/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3800e-04 - mse: 6.3800e-04 - val_loss: 9.6778e-04 - val_mse: 9.6778e-04\n",
            "Epoch 247/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3771e-04 - mse: 6.3771e-04 - val_loss: 9.7700e-04 - val_mse: 9.7700e-04\n",
            "Epoch 248/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3771e-04 - mse: 6.3771e-04 - val_loss: 9.6803e-04 - val_mse: 9.6803e-04\n",
            "Epoch 249/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3732e-04 - mse: 6.3732e-04 - val_loss: 9.6696e-04 - val_mse: 9.6696e-04\n",
            "Epoch 250/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3720e-04 - mse: 6.3720e-04 - val_loss: 9.7709e-04 - val_mse: 9.7709e-04\n",
            "Epoch 251/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3721e-04 - mse: 6.3721e-04 - val_loss: 9.6679e-04 - val_mse: 9.6679e-04\n",
            "Epoch 252/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3687e-04 - mse: 6.3687e-04 - val_loss: 9.6638e-04 - val_mse: 9.6638e-04\n",
            "Epoch 253/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3674e-04 - mse: 6.3674e-04 - val_loss: 9.7725e-04 - val_mse: 9.7725e-04\n",
            "Epoch 254/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3678e-04 - mse: 6.3678e-04 - val_loss: 9.6843e-04 - val_mse: 9.6843e-04\n",
            "Epoch 255/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3643e-04 - mse: 6.3643e-04 - val_loss: 9.7764e-04 - val_mse: 9.7764e-04\n",
            "Epoch 256/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3642e-04 - mse: 6.3642e-04 - val_loss: 9.6961e-04 - val_mse: 9.6961e-04\n",
            "Epoch 257/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3617e-04 - mse: 6.3617e-04 - val_loss: 9.7022e-04 - val_mse: 9.7022e-04\n",
            "Epoch 258/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3595e-04 - mse: 6.3595e-04 - val_loss: 9.7952e-04 - val_mse: 9.7952e-04\n",
            "Epoch 259/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3603e-04 - mse: 6.3603e-04 - val_loss: 9.7130e-04 - val_mse: 9.7130e-04\n",
            "Epoch 260/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3567e-04 - mse: 6.3567e-04 - val_loss: 9.8009e-04 - val_mse: 9.8009e-04\n",
            "Epoch 261/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3569e-04 - mse: 6.3569e-04 - val_loss: 9.7177e-04 - val_mse: 9.7177e-04\n",
            "Epoch 262/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3539e-04 - mse: 6.3539e-04 - val_loss: 9.7216e-04 - val_mse: 9.7216e-04\n",
            "Epoch 263/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3520e-04 - mse: 6.3520e-04 - val_loss: 9.7992e-04 - val_mse: 9.7992e-04\n",
            "Epoch 264/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3524e-04 - mse: 6.3524e-04 - val_loss: 9.7229e-04 - val_mse: 9.7229e-04\n",
            "Epoch 265/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3486e-04 - mse: 6.3486e-04 - val_loss: 9.7189e-04 - val_mse: 9.7189e-04\n",
            "Epoch 266/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3473e-04 - mse: 6.3473e-04 - val_loss: 9.7147e-04 - val_mse: 9.7147e-04\n",
            "Epoch 267/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3456e-04 - mse: 6.3456e-04 - val_loss: 9.7196e-04 - val_mse: 9.7196e-04\n",
            "Epoch 268/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3444e-04 - mse: 6.3444e-04 - val_loss: 9.8097e-04 - val_mse: 9.8097e-04\n",
            "Epoch 269/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3453e-04 - mse: 6.3453e-04 - val_loss: 9.7195e-04 - val_mse: 9.7195e-04\n",
            "Epoch 270/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3407e-04 - mse: 6.3407e-04 - val_loss: 9.7206e-04 - val_mse: 9.7206e-04\n",
            "Epoch 271/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3397e-04 - mse: 6.3397e-04 - val_loss: 9.7140e-04 - val_mse: 9.7140e-04\n",
            "Epoch 272/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3380e-04 - mse: 6.3380e-04 - val_loss: 9.7100e-04 - val_mse: 9.7100e-04\n",
            "Epoch 273/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3362e-04 - mse: 6.3362e-04 - val_loss: 9.7906e-04 - val_mse: 9.7906e-04\n",
            "Epoch 274/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3385e-04 - mse: 6.3385e-04 - val_loss: 9.7930e-04 - val_mse: 9.7930e-04\n",
            "Epoch 275/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3360e-04 - mse: 6.3360e-04 - val_loss: 9.7155e-04 - val_mse: 9.7155e-04\n",
            "Epoch 276/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3328e-04 - mse: 6.3328e-04 - val_loss: 9.7236e-04 - val_mse: 9.7236e-04\n",
            "Epoch 277/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3309e-04 - mse: 6.3309e-04 - val_loss: 9.7962e-04 - val_mse: 9.7962e-04\n",
            "Epoch 278/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3318e-04 - mse: 6.3318e-04 - val_loss: 9.7172e-04 - val_mse: 9.7172e-04\n",
            "Epoch 279/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3285e-04 - mse: 6.3285e-04 - val_loss: 9.7289e-04 - val_mse: 9.7289e-04\n",
            "Epoch 280/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3267e-04 - mse: 6.3267e-04 - val_loss: 9.8046e-04 - val_mse: 9.8046e-04\n",
            "Epoch 281/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3277e-04 - mse: 6.3277e-04 - val_loss: 9.7263e-04 - val_mse: 9.7263e-04\n",
            "Epoch 282/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3238e-04 - mse: 6.3238e-04 - val_loss: 9.8064e-04 - val_mse: 9.8064e-04\n",
            "Epoch 283/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3248e-04 - mse: 6.3248e-04 - val_loss: 9.7294e-04 - val_mse: 9.7294e-04\n",
            "Epoch 284/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3208e-04 - mse: 6.3208e-04 - val_loss: 9.7319e-04 - val_mse: 9.7319e-04\n",
            "Epoch 285/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3196e-04 - mse: 6.3196e-04 - val_loss: 9.8333e-04 - val_mse: 9.8333e-04\n",
            "Epoch 286/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3206e-04 - mse: 6.3206e-04 - val_loss: 9.7478e-04 - val_mse: 9.7478e-04\n",
            "Epoch 287/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3166e-04 - mse: 6.3166e-04 - val_loss: 9.8314e-04 - val_mse: 9.8314e-04\n",
            "Epoch 288/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3165e-04 - mse: 6.3165e-04 - val_loss: 9.7579e-04 - val_mse: 9.7579e-04\n",
            "Epoch 289/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3136e-04 - mse: 6.3136e-04 - val_loss: 9.8428e-04 - val_mse: 9.8428e-04\n",
            "Epoch 290/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3140e-04 - mse: 6.3140e-04 - val_loss: 9.7769e-04 - val_mse: 9.7769e-04\n",
            "Epoch 291/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3109e-04 - mse: 6.3109e-04 - val_loss: 9.9042e-04 - val_mse: 9.9042e-04\n",
            "Epoch 292/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3118e-04 - mse: 6.3118e-04 - val_loss: 9.9057e-04 - val_mse: 9.9057e-04\n",
            "Epoch 293/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3091e-04 - mse: 6.3091e-04 - val_loss: 9.8386e-04 - val_mse: 9.8386e-04\n",
            "Epoch 294/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3065e-04 - mse: 6.3065e-04 - val_loss: 9.9318e-04 - val_mse: 9.9318e-04\n",
            "Epoch 295/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3062e-04 - mse: 6.3062e-04 - val_loss: 9.8529e-04 - val_mse: 9.8529e-04\n",
            "Epoch 296/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3038e-04 - mse: 6.3038e-04 - val_loss: 9.9517e-04 - val_mse: 9.9517e-04\n",
            "Epoch 297/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.3035e-04 - mse: 6.3035e-04 - val_loss: 9.8736e-04 - val_mse: 9.8736e-04\n",
            "Epoch 298/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.2999e-04 - mse: 6.2999e-04 - val_loss: 9.8835e-04 - val_mse: 9.8835e-04\n",
            "Epoch 299/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.2983e-04 - mse: 6.2983e-04 - val_loss: 9.9744e-04 - val_mse: 9.9744e-04\n",
            "Epoch 300/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 6.2994e-04 - mse: 6.2994e-04 - val_loss: 9.9000e-04 - val_mse: 9.9000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#______________________________________________________________________________\n",
        "## plot de evoluci칩n de loss (mse)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(historico.history['loss'])\n",
        "plt.plot(historico.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#______________________________________________________________________________\n",
        "#Evaluar el modelo con el fich de test\n",
        "results_test = model.evaluate(X_test, y_test)\n",
        "results_test[0]\n",
        "#resultado es una lista con los valores de loss y las m칠tricas elegidas.\n",
        "#En este caso son loss y mse que coinciden.\n",
        "\n",
        "# predicciones en test\n",
        "test_pred = model.predict(X_test)\n",
        "#crear un ndarray: columna 1 predicciones, columna 2 target\n",
        "comp = np.append(test_pred, y_test, axis = 1)\n",
        "comp_df = pd.DataFrame(comp, columns=['prediccion','target'])\n",
        "#guardar en fichero las salidas de test y target\n",
        "np.savetxt('salidas_test.txt',comp_df)\n",
        "#mostrar 10 primeras filas\n",
        "print(comp_df.iloc[:10,:])"
      ],
      "metadata": {
        "id": "u8V4zUpxrCwK",
        "outputId": "387eae72-07b4-4c78-ff3f-12b4c196ef80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 0s 2ms/step - loss: 6.6128e-04 - mse: 6.6128e-04\n",
            "   prediccion    target\n",
            "0    0.827769  0.777778\n",
            "1    0.948265  0.949495\n",
            "2    0.930566  0.919192\n",
            "3    0.745345  0.767677\n",
            "4    0.872714  0.848485\n",
            "5    0.966953  0.979798\n",
            "6    0.872881  0.888889\n",
            "7    0.917377  0.919192\n",
            "8    0.981086  0.969697\n",
            "9    0.888752  0.878788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GUARDAR RESULTADOS EN FICHEROS\n",
        "# evoluci칩n del entrenamiento\n",
        "# son los datos que se usan para construir los plots\n",
        "# En este caso, la variable 'historico' contiene los datos del 칰ltimo entrenamiento realizado\n",
        "np.savetxt('/Redes-1/historico_pm/historicoTrainLoss.txt',historico.history['loss'])\n",
        "np.savetxt('/Redes-1/historico_pm/historicoValLoss.txt',historico.history['val_loss'])\n",
        "\n",
        "errores = [historico.history['loss'][-1], historico.history['val_loss'][-1], results_test[0]]\n",
        "#lista con los errores de entrenamiento, validaci칩n y test\n",
        "\n",
        "#guarda el modelo completo\n",
        "model.save('/Redes-1/modelos_pm/modelo.h5')\n",
        "#guarda solo pesos\n",
        "model.save_weights('/Redes-1/modelos_pm/pesos.h5')\n"
      ],
      "metadata": {
        "id": "4aDRivEErOQb"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}