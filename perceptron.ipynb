{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMY+9oGlp9wCmGXev5l+xzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia-ferrer/Redes-1/blob/pm/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar colab - **github**"
      ],
      "metadata": {
        "id": "UX1I6z0_nxZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/lucia-ferrer/Redes-1.git"
      ],
      "metadata": {
        "id": "c053X5mSnuv4",
        "outputId": "a8738419-a9b9-49be-ae59-06bb54b275d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Redes-1'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 52 (delta 17), reused 37 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Redes-1/\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "O9uBPf9wo9_S",
        "outputId": "bc203442-b464-4916-f32e-17e3b4c365ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Redes-1\n",
            "ADALINE.py\t      outputs_test.csv\t   training_artificial.csv\n",
            "artificialData.csv    prueba.py\t\t   training_set.csv\n",
            "compactiv.dat\t      __pycache__\t   train.xlsx\n",
            "datos_EXCEL_NOR.xlsx  Redes-1\t\t   validation_artificial.csv\n",
            "datos_weka_NOR.arff   test_artificial.csv  validation_set.csv\n",
            "DIVIDER.py\t      test_set.csv\t   validation.xlsx\n",
            "main.py\t\t      test.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Perceptron**"
      ],
      "metadata": {
        "id": "fviwaUsLn3i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Regression problem: MLP con Keras \"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# CARGAR DATOS compactiv\n",
        "# Cambiar par치metros correspondientes si el delimitador no es una coma, o si el archivo contiene cabeceras\n",
        "#pueden ser numpy arrays o dataframes\n",
        "#en este caso probamos con ndarrays\n",
        "train_set = pd.read_csv('training_set.csv', header='infer', delimiter=',')\n",
        "valid_set = pd.read_csv('validation_set.csv', header='infer', delimiter=',')\n",
        "test_set = pd.read_csv('test_set.csv', header='infer', delimiter=',')\n",
        "\n",
        "# SELECCION DE LA SALIDA. Num de columna del target.\n",
        "y_train = np.array(train_set.iloc[:,-1:])\n",
        "X_train = np.array(train_set.iloc[: , :-1])\n",
        "y_valid = np.array(valid_set.iloc[:,-1:])\n",
        "X_valid = np.array(valid_set.iloc[: , :-1])\n",
        "y_test = np.array(test_set.iloc[:,-1:])\n",
        "X_test = np.array(test_set.iloc[: , :-1])\n",
        "num_train_samples=len(y_train)\n"
      ],
      "metadata": {
        "id": "Gwt4RT1ekrCW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPROBAR DIMENSIONES DE LOS DATOS\n",
        "print('X_train: ',X_train.shape)\n",
        "print('y_train: ',y_train.shape)\n",
        "print('X_valid: ',X_valid.shape)\n",
        "print('y_valid: ',y_valid.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "metadata": {
        "id": "vOCztVDLp-E0",
        "outputId": "e250156c-5cbc-4c5c-bd8d-e8c7babeceef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (5733, 21)\n",
            "y_train:  (5733, 1)\n",
            "X_valid:  (1228, 21)\n",
            "y_valid:  (1228, 1)\n",
            "X_test:  (1228, 21)\n",
            "y_test:  (1228, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la entrada de la red\n",
        "input_shape=(X_train.shape [1],) #crea una tupla (21,)\n"
      ],
      "metadata": {
        "id": "aLSLzU2-qBjw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funciones con diferentes modelos\n",
        "def create_PM_sigmoid(num_hidden_neurons = 50):\n",
        "  #1 capa oculta y 1 neurona de salida con sigmoide\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def create_PM_relu(num_hidden_neurons = 50):\n",
        "  #1 capa oculta con relu y 1 neurona de salida lineal\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dense(1,activation='linear'))\n",
        "  return model\n",
        "\n",
        "#modelo lineal, solo para comparar con el programa desarrollado.\n",
        "def create_lineal():\n",
        "  # Una sola neurona lineal (Adaline)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1, input_shape=input_shape, activation='linear'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "A__kABVUqIk-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionar el modelo llamando a la funci칩n correspondiente\n",
        "#model=create_PM_relu(100) # 1 capa relu con 100 neuronas y salida sigmoid\n",
        "model=create_PM_sigmoid(20) # 1 capa sigmoid con 20 neuronas y salida sigmoid\n",
        "#model=create_lineal() # 1 capa salida LINEAL (ADALINE)\n",
        "model.summary() #visualizar la estructura del modelo\n"
      ],
      "metadata": {
        "id": "y8NNJ_mRqTrF",
        "outputId": "76779912-9ed1-4e08-f106-93b19cb4ce32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                440       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
        "lr = 0.2\n",
        "epochs = 300\n",
        "batch_size=32 #no cambiar este valor.\n",
        "#Para poder ver la curva de validaci칩n hay que poner validation_freq=1. Tarda m치s\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0), metrics=['mse'] )\n",
        "historico = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(X_valid,y_valid),\n",
        "shuffle=False, validation_freq=1)\n"
      ],
      "metadata": {
        "id": "yZksWPqTqYYZ",
        "outputId": "fbd0e2ac-93cd-46f5-9423-8cac6e55b0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 2/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 3/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0310 - val_mse: 0.0310\n",
            "Epoch 4/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0306 - val_mse: 0.0306\n",
            "Epoch 5/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 6/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 7/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 8/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 9/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 10/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 11/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 12/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 13/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 14/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 15/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 16/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 17/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 18/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0185 - val_mse: 0.0185\n",
            "Epoch 19/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0174 - val_mse: 0.0174\n",
            "Epoch 20/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 21/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 22/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 23/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 24/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 25/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 26/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 27/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 28/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 29/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 30/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 31/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 32/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 33/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 34/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 35/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 36/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 37/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0074 - val_mse: 0.0074\n",
            "Epoch 38/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0072 - val_mse: 0.0072\n",
            "Epoch 39/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0071 - val_mse: 0.0071\n",
            "Epoch 40/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0069 - val_mse: 0.0069\n",
            "Epoch 41/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0068 - val_mse: 0.0068\n",
            "Epoch 42/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0066 - val_mse: 0.0066\n",
            "Epoch 43/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0065 - val_mse: 0.0065\n",
            "Epoch 44/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0064 - val_mse: 0.0064\n",
            "Epoch 45/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0063 - val_mse: 0.0063\n",
            "Epoch 46/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0063 - val_mse: 0.0063\n",
            "Epoch 47/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0062 - val_mse: 0.0062\n",
            "Epoch 48/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0061 - val_mse: 0.0061\n",
            "Epoch 49/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0060 - val_mse: 0.0060\n",
            "Epoch 50/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0060 - val_mse: 0.0060\n",
            "Epoch 51/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0059 - val_mse: 0.0059\n",
            "Epoch 52/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0059 - val_mse: 0.0059\n",
            "Epoch 53/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0058 - val_mse: 0.0058\n",
            "Epoch 54/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0058 - val_mse: 0.0058\n",
            "Epoch 55/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0058 - val_mse: 0.0058\n",
            "Epoch 56/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 57/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 58/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 59/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 60/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 61/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 62/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 63/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 64/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 65/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 66/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 67/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 68/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 69/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 70/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 71/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 72/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 73/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 74/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 75/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 76/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 77/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 78/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 79/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 80/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 81/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 82/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 83/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 84/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 85/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 86/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 87/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 88/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 89/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 90/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 91/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 92/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 93/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 94/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 95/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 96/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 97/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 98/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 99/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 100/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 101/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 102/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 103/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 104/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 105/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 106/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 107/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 108/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 109/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 110/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 111/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 112/300\n",
            "180/180 [==============================] - 0s 3ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 113/300\n",
            "180/180 [==============================] - 1s 5ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 114/300\n",
            "180/180 [==============================] - 1s 7ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 115/300\n",
            "180/180 [==============================] - 1s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 116/300\n",
            "180/180 [==============================] - 1s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 117/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 118/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 119/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 120/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 121/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 122/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 123/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 124/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 125/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 126/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 127/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 128/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 129/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 130/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 131/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 132/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 133/300\n",
            "180/180 [==============================] - 1s 3ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 134/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 135/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 136/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 137/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 138/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 139/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 140/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 141/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 142/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 143/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 144/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 145/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 146/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 147/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 148/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 149/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 150/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 151/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 152/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 153/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 154/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 155/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 156/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 157/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 158/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 159/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 160/300\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 161/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 162/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 163/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 164/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 165/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 166/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 167/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 168/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 169/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 170/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 171/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 172/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 173/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 174/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 175/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 176/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 177/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 178/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 179/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 180/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 181/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 182/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 183/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 184/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 185/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 186/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 187/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 188/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 189/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 190/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 191/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 192/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 193/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 194/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 195/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 196/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 197/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 198/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 199/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 200/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 201/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 202/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 203/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 204/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 205/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 206/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 207/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 208/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 209/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 210/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 211/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 212/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 213/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 214/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 215/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 216/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 217/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 218/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 219/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 220/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 221/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 222/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 223/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 224/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 225/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 226/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 227/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 228/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 229/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 230/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 231/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 232/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 233/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 234/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 235/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 236/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 237/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 238/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 239/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 240/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 241/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 242/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 243/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 244/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 245/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 246/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 247/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 248/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 249/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 250/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 251/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 252/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 253/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 254/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 255/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 256/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 257/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 258/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 259/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 260/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 261/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 262/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 263/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 264/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 265/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 266/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 267/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 268/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 269/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 270/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 271/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 272/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 273/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 274/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 275/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 276/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 277/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 278/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 279/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 280/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 281/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 282/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 283/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 284/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 285/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 286/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 287/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 288/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 289/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 290/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 291/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 292/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 293/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 294/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 295/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 296/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 297/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 298/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 299/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 300/300\n",
            "180/180 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot de evoluci칩n de loss (mse)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(historico.history['loss'])\n",
        "plt.plot(historico.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u8V4zUpxrCwK",
        "outputId": "33883351-6ce7-4c0c-dec2-e96be16393e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluar el modelo con el fich de test\n",
        "results_test = model.evaluate(X_test, y_test)\n",
        "results_test[0]\n",
        "#resultado es una lista con los valores de loss y las m칠tricas elegidas.\n",
        "#En este caso son loss y mse que coinciden.\n",
        "\n",
        "# predicciones en test\n",
        "test_pred = model.predict(X_test)\n",
        "#crear un ndarray: columna 1 predicciones, columna 2 target\n",
        "comp = np.append(test_pred, y_test, axis = 1)\n",
        "comp_df = pd.DataFrame(comp, columns=['prediccion','target'])\n",
        "#guardar en fichero las salidas de test y target\n",
        "np.savetxt('salidas_test.txt',comp_df)\n",
        "#mostrar 10 primeras filas\n",
        "print(comp_df.iloc[:10,:])"
      ],
      "metadata": {
        "id": "DKc72y46rFH1",
        "outputId": "bc8e3258-674d-4d20-daac-4d34ba17baf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 0s 2ms/step - loss: 0.0032 - mse: 0.0032\n",
            "   prediccion    target\n",
            "0    0.940598  0.909091\n",
            "1    0.851709  0.898990\n",
            "2    0.876146  0.898990\n",
            "3    0.964561  0.969697\n",
            "4    0.810792  0.838384\n",
            "5    0.857658  0.878788\n",
            "6    0.820072  0.797980\n",
            "7    0.864566  0.929293\n",
            "8    0.973302  0.979798\n",
            "9    0.913432  0.858586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GUARDAR RESULTADOS EN FICHEROS\n",
        "# evoluci칩n del entrenamiento\n",
        "# son los datos que se usan para construir los plots\n",
        "# En este caso, la variable 'historico' contiene los datos del 칰ltimo entrenamiento realizado\n",
        "np.savetxt('historicoTrainLoss.txt',historico.history['loss'])\n",
        "np.savetxt('historicoValLoss.txt',historico.history['val_loss'])\n",
        "errores = [historico.history['loss'][-1], historico.history['val_loss'][-1], results_test[0]]\n",
        "#lista con los errores de entrenamiento, validaci칩n y test\n",
        "\n",
        "#guarda el modelo completo\n",
        "model.save('modelo.h5')\n",
        "#guarda solo pesos\n",
        "model.save_weights('pesos.h5')\n"
      ],
      "metadata": {
        "id": "4aDRivEErOQb"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}