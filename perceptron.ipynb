{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "XnYQJq0I9bVT",
        "tiSsNJEpud5l"
      ],
      "authorship_tag": "ABX9TyM6V12MN+XksMhJkLoOtUTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia-ferrer/Redes-1/blob/pm/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar colab - **github**"
      ],
      "metadata": {
        "id": "UX1I6z0_nxZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lucia-ferrer/Redes-1.git"
      ],
      "metadata": {
        "id": "c053X5mSnuv4",
        "outputId": "60ed645a-1634-42e7-a8a2-7aa082df17f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Redes-1'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 58 (delta 20), reused 37 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "X92EsYwGkzq8",
        "outputId": "378c709f-ae48-4d7f-fe26-a28b222a1260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTAR\n"
      ],
      "metadata": {
        "id": "fviwaUsLn3i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Regression problem: MLP con Keras \"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras_tuner as kt #Librería de Keras Tuner\n",
        "\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# CARGAR DATOS compactiv\n",
        "# Cambiar parámetros correspondientes si el delimitador no es una coma, o si el archivo contiene cabeceras\n",
        "# pueden ser numpy arrays o dataframes en este caso probamos con ndarrays\n",
        "\n",
        "train_set = pd.read_csv('/content/Redes-1/training_set.csv', header='infer', delimiter=',')\n",
        "valid_set = pd.read_csv('/content/Redes-1/validation_set.csv', header='infer', delimiter=',')\n",
        "test_set = pd.read_csv('/content/Redes-1/validation_set.csv', header='infer', delimiter=',')\n",
        "\n",
        "# SELECCION DE LA SALIDA. Num de columna del target.\n",
        "y_train = np.array(train_set.iloc[:,-1:])\n",
        "x_train = np.array(train_set.iloc[: , :-1])\n",
        "y_valid = np.array(valid_set.iloc[:,-1:])\n",
        "x_valid = np.array(valid_set.iloc[: , :-1])\n",
        "y_test = np.array(test_set.iloc[:,-1:])\n",
        "X_test = np.array(test_set.iloc[: , :-1])\n",
        "num_train_samples=len(y_train)\n"
      ],
      "metadata": {
        "id": "Gwt4RT1ekrCW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELOS PROFE\n"
      ],
      "metadata": {
        "id": "XnYQJq0I9bVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPROBAR DIMENSIONES DE LOS DATOS\n",
        "print('X_train: ',X_train.shape)\n",
        "print('y_train: ',y_train.shape)\n",
        "print('X_valid: ',X_valid.shape)\n",
        "print('y_valid: ',y_valid.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "metadata": {
        "id": "vOCztVDLp-E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la entrada de la red\n",
        "input_shape=(X_train.shape [1],) #crea una tupla (21,)\n",
        "\n",
        "#funciones con diferentes modelos\n",
        "def create_PM_sigmoid(num_hidden_neurons = 50):\n",
        "  #1 capa oculta y 1 neurona de salida con sigmoide\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='sigmoid'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "def create_PM_relu(num_hidden_neurons = 50):\n",
        "  #1 capa oculta con relu y 1 neurona de salida lineal\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_hidden_neurons, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dense(1,activation='linear'))\n",
        "  return model\n",
        "\n",
        "#modelo lineal, solo para comparar con el programa desarrollado.\n",
        "def create_lineal():\n",
        "  # Una sola neurona lineal (Adaline)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1, input_shape=input_shape, activation='linear'))\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "A__kABVUqIk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionar el modelo llamando a la función correspondiente\n",
        "model=create_PM_relu(20) # 1 capa relu con 20 neuronas y salida lineal\n",
        "#model=create_PM_sigmoid(20) # 1 capa sigmoid con 20 neuronas y salida sigmoid\n",
        "#model=create_lineal() # 1 capa salida LINEAL (ADALINE)\n",
        "model.summary() #visualizar la estructura del modelo\n"
      ],
      "metadata": {
        "id": "y8NNJ_mRqTrF",
        "outputId": "08ab8dd1-715d-4db6-d121-cc5f72fba50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                440       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURAR MODELO Y ENTRENAMIENTO\n",
        "lr = 0.2\n",
        "epochs = 300\n",
        "batch_size=32 #no cambiar este valor.\n",
        "#Para poder ver la curva de validación hay que poner validation_freq=1. Tarda más\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0), metrics=['mse'] )\n",
        "historico = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(X_valid,y_valid),\n",
        "shuffle=False, validation_freq=1)\n"
      ],
      "metadata": {
        "id": "yZksWPqTqYYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#______________________________________________________________________________\n",
        "## plot de evolución de loss (mse)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(historico.history['loss'])\n",
        "plt.plot(historico.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#______________________________________________________________________________\n",
        "#Evaluar el modelo con el fich de test\n",
        "results_test = model.evaluate(X_test, y_test)\n",
        "results_test[0]\n",
        "#resultado es una lista con los valores de loss y las métricas elegidas.\n",
        "#En este caso son loss y mse que coinciden.\n",
        "\n",
        "# predicciones en test\n",
        "test_pred = model.predict(X_test)\n",
        "#crear un ndarray: columna 1 predicciones, columna 2 target\n",
        "comp = np.append(test_pred, y_test, axis = 1)\n",
        "comp_df = pd.DataFrame(comp, columns=['prediccion','target'])\n",
        "#guardar en fichero las salidas de test y target\n",
        "np.savetxt('salidas_test.txt',comp_df)\n",
        "#mostrar 10 primeras filas\n",
        "print(comp_df.iloc[:10,:])"
      ],
      "metadata": {
        "id": "u8V4zUpxrCwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FICHEROS\n"
      ],
      "metadata": {
        "id": "tiSsNJEpud5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GUARDAR RESULTADOS EN FICHEROS\n",
        "# evolución del entrenamiento\n",
        "# son los datos que se usan para construir los plots\n",
        "# En este caso, la variable 'historico' contiene los datos del último entrenamiento realizado\n",
        "np.savetxt('/Redes-1/historico_pm/historicoTrainLoss.txt',historico.history['loss'])\n",
        "np.savetxt('/Redes-1/historico_pm/historicoValLoss.txt',historico.history['val_loss'])\n",
        "\n",
        "errores = [historico.history['loss'][-1], historico.history['val_loss'][-1], results_test[0]]\n",
        "#lista con los errores de entrenamiento, validación y test\n",
        "\n",
        "#guarda el modelo completo\n",
        "model.save('/Redes-1/modelos_pm/modelo.h5')\n",
        "#guarda solo pesos\n",
        "model.save_weights('/Redes-1/modelos_pm/pesos.h5')\n"
      ],
      "metadata": {
        "id": "4aDRivEErOQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HIPERPARAMETRO"
      ],
      "metadata": {
        "id": "-MpMBYuMoNCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la entrada de la red\n",
        "input_shape=(x_train.shape [1],) #crea una tupla (21,)\n",
        "\n",
        "# ______________________ CREACION CON HIPERPARAMETROS__________________________\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  for _ in range(hp.Int(\"num_layers\", 1, 3)):\n",
        "    model.add( Dense(\n",
        "        # tune number of neurons\n",
        "        units = hp.Int(\"units\", min_value=20, max_value=100, step=20),\n",
        "        input_shape = input_shape, \n",
        "        #tune the activation function \n",
        "        activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
        "        )\n",
        "    )\n",
        "    # Tune whether to use dropout. --> Used to avoid Overfitting.\n",
        "    if hp.Boolean('dropout'):\n",
        "      model.add(Dropout(rate=0.25))\n",
        "\n",
        "  #Output layer\n",
        "  model.add(Dense(1, input_shape=input_shape, activation='relu'))\n",
        "  # Tune lr\n",
        "  lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "  \n",
        "  model.compile(\n",
        "      loss='mean_squared_error', \n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=lr, momentum=0), \n",
        "      metrics=['mse'] )\n",
        "  return model\n",
        "\n",
        "build_model(kt.HyperParameters())"
      ],
      "metadata": {
        "id": "ueyIJc1Lquam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01030e8-ab68-4338-f726-579b1a4b4f6d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f103a675510>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    hypermodel = build_model, \n",
        "    objective = 'mse',\n",
        "    seed = 50,\n",
        "    max_trials = 3,\n",
        "    )\n",
        "\n",
        "tuner.search_space_summary()\n"
      ],
      "metadata": {
        "id": "YaHosVSsoTxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c40c11-3800-4557-d3a5-aead13fde824"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 100, 'step': 20, 'sampling': None}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_valid, y_valid))\n",
        "best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "id": "G1_Jtt5MvB3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a1e666-df28-4988-92d9-f17d193ee9bc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este ejemplo hemos configurado algunos de los elementos del algoritmo de búsqueda de la siguiente manera:\n",
        "\n",
        "- Función objetivo (objetive) es la función que utilizaremos para encontrar el mejor modelo.\n",
        "- Semilla (seed) es un valor numérico que nos permitirá repetir la experimentación en caso de que sea necesario.\n",
        "- Número de intentos (max_trials) es el número de iteraciones del proceso de búsqueda. Este valor se puede considerar como condición de parada del algoritmo de búsqueda.\n",
        "- Número de ejecuciones por intento (executions_per_trial) es el número de ejecuciones de cada proceso de entrenamiento."
      ],
      "metadata": {
        "id": "pDjhZjwqpDOh"
      }
    }
  ]
}